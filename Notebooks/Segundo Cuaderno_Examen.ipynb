{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0287dd64-1f9a-4c0d-b486-d3ed4e101848",
   "metadata": {},
   "source": [
    "# Examen Segundo Interciclo — Cuaderno 2  \n",
    "**Tema:** Predicción con reentrenamiento (feedback) con MLflow  \n",
    "**Autores:** Zahid Armijos y Cristopher Jara — **Usuario GitHub:** criss16-nimoi  \n",
    "**Experimento MLflow:** `Examen_Segundo_Interciclo`\n",
    "\n",
    "> Este cuaderno permite predecir imágenes, corregir etiquetas y reentrenar el modelo guardando cada run en MLflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22871ef1-0512-443c-8e30-c456547a6545",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "1) Realizar predicciones sobre nuevas imágenes.  \n",
    "2) Permitir **feedback** (corrección de etiqueta).  \n",
    "3) Ejecutar **reentrenamiento incremental** y registrar cada run en **MLflow**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee25d3-53da-4eb4-bc3a-483d596ceddd",
   "metadata": {},
   "source": [
    "## Dataset y rutas\n",
    "Este cuaderno trabaja con:\n",
    "\n",
    "- Dataset principal: `dataset_animales/raw/{vaca,cerdo,gallina}`\n",
    "- Imágenes de prueba: `test_images/`\n",
    "- Feedback (se crea automáticamente): `feedback_images/` y `feedback_labels.csv`\n",
    "- MLflow tracking: `./mlruns` (en la carpeta del proyecto)\n",
    "\n",
    "> Si el conteo por clase sale en **0**, la ruta está mal o la carpeta está vacía.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9212ac3b-6891-4fc8-bb54-7fba97b0ea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: C:\\Users\\leoos\\Examen_Segundo_Interciclo\n",
      "RAW_DIR exists? True\n",
      "TEST_DIR exists? True\n",
      "CLASSES: ['vaca', 'cerdo', 'gallina']\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELDA 1) IMPORTS + CONFIG + RUTAS (Examen_Segundo_Interciclo)\n",
    "# =========================================================\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "# -------- CONFIG --------\n",
    "CLASSES = [\"vaca\", \"cerdo\", \"gallina\"]   # en minúsculas (como tus carpetas)\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "SEED = 7\n",
    "\n",
    "# Proyecto = carpeta donde está abierto el notebook\n",
    "PROJECT_DIR = Path.cwd().resolve()\n",
    "\n",
    "DATASET_DIR = PROJECT_DIR / \"dataset_animales\"\n",
    "RAW_DIR = DATASET_DIR / \"raw\"\n",
    "MODELS_DIR = DATASET_DIR / \"models\"\n",
    "\n",
    "TEST_DIR = PROJECT_DIR / \"test_images\"\n",
    "\n",
    "FEEDBACK_DIR = DATASET_DIR / \"feedback_data\"\n",
    "FEEDBACK_IMG_DIR = FEEDBACK_DIR / \"images\"\n",
    "FEEDBACK_LABELS_CSV = FEEDBACK_DIR / \"labels.csv\"\n",
    "\n",
    "BEST_MODEL_PATH = MODELS_DIR / \"best_multilabel.keras\"\n",
    "THRESH_PATH = MODELS_DIR / \"threshold.json\"\n",
    "\n",
    "# MLflow (FILE STORE, sin sqlite) -> evita problemas de schema\n",
    "MLRUNS_DIR = PROJECT_DIR / \"mlruns\"\n",
    "EXPERIMENT_NAME = \"Examen_Segundo_Interciclo\"\n",
    "\n",
    "IMG_EXTS = {\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\",\".tif\",\".tiff\"}\n",
    "\n",
    "\n",
    "def ensure_dirs():\n",
    "    for p in [DATASET_DIR, RAW_DIR, MODELS_DIR, TEST_DIR, FEEDBACK_DIR, FEEDBACK_IMG_DIR, MLRUNS_DIR]:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def list_images(folder: Path):\n",
    "    files = []\n",
    "    for p in folder.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in IMG_EXTS:\n",
    "            files.append(p)\n",
    "    return sorted(files, key=lambda x: str(x).lower())\n",
    "\n",
    "def ensure_feedback_csv():\n",
    "    if not FEEDBACK_LABELS_CSV.exists():\n",
    "        FEEDBACK_LABELS_CSV.write_text(\"filename,labels,timestamp\\n\", encoding=\"utf-8\")\n",
    "\n",
    "ensure_dirs()\n",
    "\n",
    "print(\"CWD:\", PROJECT_DIR)\n",
    "print(\"RAW_DIR exists?\", RAW_DIR.exists())\n",
    "print(\"TEST_DIR exists?\", TEST_DIR.exists())\n",
    "print(\"CLASSES:\", CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b85c3c50-51e6-4a75-809c-321c354bd469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tracking URI: file:///C:/Users/leoos/Examen_Segundo_Interciclo/mlruns\n",
      " Experimentos: ['Examen_Segundo_Interciclo']\n",
      " Para abrir la UI, usa este comando:\n",
      "mlflow ui --backend-store-uri \"file:///C:/Users/leoos/Examen_Segundo_Interciclo/mlruns\" --port 5000\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import time, json, tempfile, shutil\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# ========= CONFIG MLflow (FIJO) =========\n",
    "PROJECT_DIR = Path.cwd()\n",
    "MLRUNS_DIR = PROJECT_DIR / \"mlruns\"\n",
    "EXPERIMENT_NAME = \"Examen_Segundo_Interciclo\"\n",
    "\n",
    "def setup_mlflow():\n",
    "    \"\"\"\n",
    "    Usa SIEMPRE file store (mlruns) para que lo veas en MLflow UI con:\n",
    "    mlflow ui --backend-store-uri \"file:///.../mlruns\"\n",
    "    \"\"\"\n",
    "    tracking_uri = MLRUNS_DIR.resolve().as_uri()  # file:///C:/.../mlruns\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    return tracking_uri\n",
    "\n",
    "def safe_log_keras_model(model: keras.Model, name: str = \"model\"):\n",
    "    \"\"\"\n",
    "    Loguea el modelo sin signature/input_example (evita FileNotFoundError en Temp).\n",
    "    Si mlflow.keras.log_model falla por compatibilidad, hace fallback y lo sube como artifacts.\n",
    "    \"\"\"\n",
    "    pip_reqs = [\n",
    "        f\"tensorflow=={tf.__version__}\",\n",
    "        \"numpy\",\n",
    "        f\"mlflow=={mlflow.__version__}\",\n",
    "    ]\n",
    "    try:\n",
    "        # MLflow nuevo (recomendado)\n",
    "        mlflow.keras.log_model(model, name=name, pip_requirements=pip_reqs)\n",
    "        return\n",
    "    except TypeError:\n",
    "        # MLflow viejo (compatibilidad)\n",
    "        mlflow.keras.log_model(model, artifact_path=name, pip_requirements=pip_reqs)\n",
    "        return\n",
    "    except Exception as e:\n",
    "        # Fallback: guardo en carpeta temporal y lo subo como artefacto normal\n",
    "        tmp_dir = Path(tempfile.mkdtemp())\n",
    "        out_dir = tmp_dir / name\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        try:\n",
    "            model.save(out_dir / \"model.keras\")\n",
    "            mlflow.log_artifacts(str(out_dir), artifact_path=name)\n",
    "        finally:\n",
    "            shutil.rmtree(tmp_dir, ignore_errors=True)\n",
    "\n",
    "def train_and_log(run_name: str, model: keras.Model, train_ds, val_ds, epochs: int, lr: float, note: str,\n",
    "                  CLASSES=None, THRESH_PATH: Path=None, BEST_MODEL_PATH: Path=None):\n",
    "    \"\"\"\n",
    "    Entrena, registra métricas, guarda threshold.json y guarda el modelo en MLflow.\n",
    "    IMPORTANTE: retorna float (macro_f1), NO retorna History.\n",
    "    \"\"\"\n",
    "    setup_mlflow()\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.set_tag(\"note\", note)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "        if CLASSES is not None:\n",
    "            mlflow.log_param(\"classes\", \"|\".join(CLASSES))\n",
    "\n",
    "        # Entrenamiento\n",
    "        hist = model.fit(train_ds, validation_data=val_ds, epochs=epochs, verbose=1)\n",
    "\n",
    "        # Log últimas métricas del history\n",
    "        last = {k: float(v[-1]) for k, v in hist.history.items() if len(v)}\n",
    "        for k, v in last.items():\n",
    "            mlflow.log_metric(k.replace(\"@\",\"_\"), v)\n",
    "\n",
    "        # Guardar modelo \"best\" local (si lo usas en tu flujo)\n",
    "        if BEST_MODEL_PATH is not None:\n",
    "            BEST_MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "            model.save(BEST_MODEL_PATH)\n",
    "\n",
    "        # Guardar thresholds si existe THRESH_PATH (opcional)\n",
    "        if THRESH_PATH is not None:\n",
    "            THRESH_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "            # Si tú ya calculas thresholds en otra parte, aquí solo se asegura que exista\n",
    "            if not THRESH_PATH.exists():\n",
    "                obj = {\"thresholds\": {}, \"created_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "                THRESH_PATH.write_text(json.dumps(obj, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "            # IMPORTANTE: sin artifact_path=\"artifacts\" para que NO cree artifacts/artifacts/\n",
    "            mlflow.log_artifact(str(THRESH_PATH))\n",
    "\n",
    "        # Guardar modelo en MLflow (aparece en el RUN -> Artifacts -> model/)\n",
    "        safe_log_keras_model(model, name=\"model\")\n",
    "\n",
    "        # Macro-F1 si existe en history (si no, devuelvo 0.0)\n",
    "        macro_f1 = 0.0\n",
    "        for key in [\"val_f1_macro\", \"f1_macro\", \"val_f1\", \"f1\"]:\n",
    "            if key in hist.history:\n",
    "                macro_f1 = float(np.max(hist.history[key]))\n",
    "                break\n",
    "\n",
    "        mlflow.log_metric(\"macro_f1_reported\", macro_f1)\n",
    "        return macro_f1\n",
    "\n",
    "# ========= Verificación rápida =========\n",
    "tracking_uri = setup_mlflow()\n",
    "client = MlflowClient()\n",
    "print(\" Tracking URI:\", mlflow.get_tracking_uri())\n",
    "print(\" Experimentos:\", [e.name for e in client.search_experiments()])\n",
    "print(\" Para abrir la UI, usa este comando:\")\n",
    "print(f'mlflow ui --backend-store-uri \"{MLRUNS_DIR.resolve().as_uri()}\" --port 5000')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1281cf98-9a02-4b88-a4c3-77ffb341dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# CELDA 2) SETUP MLFLOW (Experimento: Examen_Segundo_Interciclo)\n",
    "# =========================================================\n",
    "def setup_mlflow():\n",
    "    ensure_dirs()\n",
    "\n",
    "    # tracking uri tipo file:///.../mlruns\n",
    "    mlflow.set_tracking_uri(MLRUNS_DIR.as_uri())\n",
    "\n",
    "    client = MlflowClient()\n",
    "    exp = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if exp is None:\n",
    "        exp_id = client.create_experiment(EXPERIMENT_NAME)\n",
    "    else:\n",
    "        exp_id = exp.experiment_id\n",
    "\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    return exp_id\n",
    "\n",
    "def safe_log_keras_model(model: keras.Model, name: str = \"model\"):\n",
    "    \"\"\"\n",
    "    Versión estable en Windows:\n",
    "    - No usa input_example ni signature (evita FileNotFoundError en Temp)\n",
    "    - Fija pip_requirements para evitar el warning de inferencia\n",
    "    - Fallback: si MLflow falla igual, guarda el .keras como artifact\n",
    "    \"\"\"\n",
    "    pip_reqs = [\n",
    "        f\"tensorflow=={tf.__version__}\",\n",
    "        f\"keras=={keras.__version__}\",\n",
    "        f\"mlflow=={mlflow.__version__}\",\n",
    "        \"numpy\",\n",
    "        \"pillow\",\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # MLflow nuevo: usa name=\n",
    "        mlflow.keras.log_model(\n",
    "            model,\n",
    "            name=name,\n",
    "            pip_requirements=pip_reqs,\n",
    "        )\n",
    "        return\n",
    "\n",
    "    except TypeError:\n",
    "        # MLflow viejo: usa artifact_path=\n",
    "        mlflow.keras.log_model(\n",
    "            model,\n",
    "            artifact_path=name,\n",
    "            pip_requirements=pip_reqs,\n",
    "        )\n",
    "        return\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"⚠️ MLflow falló guardando el modelo (tema Temp en Windows). Haré fallback a artifact .keras.\")\n",
    "        tmp_path = PROJECT_DIR / \"_model_fallback.keras\"\n",
    "        model.save(tmp_path)\n",
    "        mlflow.log_artifact(str(tmp_path), artifact_path=\"model_fallback\")\n",
    "        try:\n",
    "            tmp_path.unlink()\n",
    "        except Exception:\n",
    "            pass\n",
    "        print(\"✅ Fallback guardado en artifacts/model_fallback\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53361ddd-4418-4350-afbc-34452229f220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw train: 122 | Raw val: 33\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELDA 3) DATASET: RAW RECORDS (raw/vaca, raw/cerdo, raw/gallina)\n",
    "# =========================================================\n",
    "def build_raw_records(train_split=0.8):\n",
    "    rng = np.random.default_rng(SEED)\n",
    "    train, val = [], []\n",
    "\n",
    "    for cls_idx, cls in enumerate(CLASSES):\n",
    "        cls_dir = RAW_DIR / cls\n",
    "        imgs = list_images(cls_dir)\n",
    "\n",
    "        rng.shuffle(imgs)\n",
    "        n_train = int(len(imgs) * train_split)\n",
    "\n",
    "        for i, p in enumerate(imgs):\n",
    "            y = np.zeros((NUM_CLASSES,), dtype=np.float32)\n",
    "            y[cls_idx] = 1.0\n",
    "            item = (str(p), y)\n",
    "            (train if i < n_train else val).append(item)\n",
    "\n",
    "    rng.shuffle(train)\n",
    "    rng.shuffle(val)\n",
    "    return train, val\n",
    "\n",
    "raw_train, raw_val = build_raw_records(train_split=0.8)\n",
    "print(\"Raw train:\", len(raw_train), \"| Raw val:\", len(raw_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3b5f8459-a95a-4d16-9359-78fe0b37aabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback actual: 6\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELDA 4) FEEDBACK: GUARDAR Y CARGAR (multi-label)\n",
    "# =========================================================\n",
    "def load_feedback_records():\n",
    "    ensure_feedback_csv()\n",
    "    if not FEEDBACK_LABELS_CSV.exists():\n",
    "        return []\n",
    "\n",
    "    lines = FEEDBACK_LABELS_CSV.read_text(encoding=\"utf-8\").strip().splitlines()\n",
    "    if len(lines) <= 1:\n",
    "        return []\n",
    "\n",
    "    recs = []\n",
    "    for row in lines[1:]:\n",
    "        parts = row.split(\",\", 2)\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "\n",
    "        filename, labels_csv, ts = parts[0], parts[1], parts[2]\n",
    "        img_path = FEEDBACK_IMG_DIR / filename\n",
    "        if not img_path.exists():\n",
    "            continue\n",
    "\n",
    "        labels = labels_csv.split(\"|\") if labels_csv else []\n",
    "        y = np.zeros((NUM_CLASSES,), dtype=np.float32)\n",
    "        for lab in labels:\n",
    "            if lab in CLASSES:\n",
    "                y[CLASSES.index(lab)] = 1.0\n",
    "\n",
    "        recs.append((str(img_path), y))\n",
    "    return recs\n",
    "\n",
    "def save_feedback(img_path: Path, selected_labels):\n",
    "    ensure_dirs()\n",
    "    ensure_feedback_csv()\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_name = f\"{img_path.stem}_{ts}{img_path.suffix.lower()}\"\n",
    "    out_path = FEEDBACK_IMG_DIR / out_name\n",
    "    shutil.copy2(img_path, out_path)\n",
    "\n",
    "    labels_csv = \"|\".join(selected_labels)\n",
    "    with open(FEEDBACK_LABELS_CSV, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{out_name},{labels_csv},{ts}\\n\")\n",
    "\n",
    "    return out_path\n",
    "\n",
    "print(\"Feedback actual:\", len(load_feedback_records()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97e093e1-0d28-469e-8e59-a4ad145ac2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# CELDA 5) TF PIPELINE (decode + tf.data)\n",
    "# =========================================================\n",
    "def decode_image(path: tf.Tensor) -> tf.Tensor:\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = preprocess_input(img)  # EfficientNet preprocess\n",
    "    return img\n",
    "\n",
    "def make_ds(records, training: bool, shuffle: bool):\n",
    "    paths = np.array([r[0] for r in records], dtype=object)\n",
    "    labels = np.stack([r[1] for r in records]).astype(np.float32)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if shuffle and training:\n",
    "        ds = ds.shuffle(buffer_size=min(len(records), 2000), seed=SEED, reshuffle_each_iteration=True)\n",
    "\n",
    "    ds = ds.map(lambda p, y: (decode_image(p), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e0db8b95-57e0-4f49-b649-455c190bbda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# CELDA 6) MÉTRICAS: F1Macro + THRESHOLDS (macro-f1 real)\n",
    "# =========================================================\n",
    "class F1Macro(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes: int, threshold: float = 0.35, name=\"f1_macro\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.threshold = threshold\n",
    "        self.tp = self.add_weight(shape=(num_classes,), initializer=\"zeros\", name=\"tp\")\n",
    "        self.fp = self.add_weight(shape=(num_classes,), initializer=\"zeros\", name=\"fp\")\n",
    "        self.fn = self.add_weight(shape=(num_classes,), initializer=\"zeros\", name=\"fn\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_hat = tf.cast(y_pred >= self.threshold, tf.float32)\n",
    "        tp = tf.reduce_sum(y_true * y_hat, axis=0)\n",
    "        fp = tf.reduce_sum((1.0 - y_true) * y_hat, axis=0)\n",
    "        fn = tf.reduce_sum(y_true * (1.0 - y_hat), axis=0)\n",
    "        self.tp.assign_add(tp)\n",
    "        self.fp.assign_add(fp)\n",
    "        self.fn.assign_add(fn)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.tp / (self.tp + self.fp + 1e-7)\n",
    "        recall = self.tp / (self.tp + self.fn + 1e-7)\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-7)\n",
    "        return tf.reduce_mean(f1)\n",
    "\n",
    "    def reset_states(self):\n",
    "        for v in [self.tp, self.fp, self.fn]:\n",
    "            v.assign(tf.zeros_like(v))\n",
    "\n",
    "\n",
    "def evaluate_probs(model: keras.Model, ds):\n",
    "    y_true_list, y_prob_list = [], []\n",
    "    for xb, yb in ds:\n",
    "        prob = model.predict(xb, verbose=0)\n",
    "        y_true_list.append(yb.numpy())\n",
    "        y_prob_list.append(prob)\n",
    "    y_true = np.vstack(y_true_list) if y_true_list else np.zeros((0, NUM_CLASSES), dtype=np.float32)\n",
    "    y_prob = np.vstack(y_prob_list) if y_prob_list else np.zeros((0, NUM_CLASSES), dtype=np.float32)\n",
    "    return y_true, y_prob\n",
    "\n",
    "def metrics_at_thresholds(y_true: np.ndarray, y_prob: np.ndarray, thr: np.ndarray):\n",
    "    y_hat = (y_prob >= thr.reshape(1, -1)).astype(int)\n",
    "    yt = y_true.astype(int)\n",
    "\n",
    "    tp = np.sum((yt == 1) & (y_hat == 1), axis=0)\n",
    "    fp = np.sum((yt == 0) & (y_hat == 1), axis=0)\n",
    "    fn = np.sum((yt == 1) & (y_hat == 0), axis=0)\n",
    "\n",
    "    prec = tp / (tp + fp + 1e-7)\n",
    "    rec  = tp / (tp + fn + 1e-7)\n",
    "    f1   = 2 * prec * rec / (prec + rec + 1e-7)\n",
    "    macro_f1 = float(np.mean(f1)) if f1.size else 0.0\n",
    "    return prec, rec, f1, macro_f1\n",
    "\n",
    "def find_best_thresholds(y_true: np.ndarray, y_prob: np.ndarray):\n",
    "    thrs = np.full((NUM_CLASSES,), 0.35, dtype=np.float32)\n",
    "    grid = np.linspace(0.05, 0.95, 19)\n",
    "\n",
    "    for c in range(NUM_CLASSES):\n",
    "        best_f1 = -1.0\n",
    "        best_t = 0.35\n",
    "        yt = y_true[:, c].astype(int)\n",
    "        yp = y_prob[:, c]\n",
    "        for t in grid:\n",
    "            yh = (yp >= t).astype(int)\n",
    "            tp = np.sum((yt == 1) & (yh == 1))\n",
    "            fp = np.sum((yt == 0) & (yh == 1))\n",
    "            fn = np.sum((yt == 1) & (yh == 0))\n",
    "            prec = tp / (tp + fp + 1e-7)\n",
    "            rec  = tp / (tp + fn + 1e-7)\n",
    "            f1 = 2 * prec * rec / (prec + rec + 1e-7)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_t = float(t)\n",
    "        thrs[c] = best_t\n",
    "    return thrs\n",
    "\n",
    "def save_thresholds(thr: np.ndarray):\n",
    "    obj = {\n",
    "        \"classes\": CLASSES,\n",
    "        \"thresholds\": {CLASSES[i]: float(thr[i]) for i in range(NUM_CLASSES)},\n",
    "        \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    }\n",
    "    THRESH_PATH.write_text(json.dumps(obj, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "def load_thresholds_or_default():\n",
    "    if THRESH_PATH.exists():\n",
    "        cfg = json.loads(THRESH_PATH.read_text(encoding=\"utf-8\"))\n",
    "        thr_dict = cfg.get(\"thresholds\", {})\n",
    "        return np.array([float(thr_dict.get(c, 0.35)) for c in CLASSES], dtype=np.float32)\n",
    "    return np.full((NUM_CLASSES,), 0.35, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f5da9b3c-8efc-47ed-972d-a96ed37801c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo listo: True | Thresholds: True\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELDA 7) MODELO + LOAD BEST\n",
    "# =========================================================\n",
    "def build_model(lr=1e-3, threshold_metric=0.35):\n",
    "    base = keras.applications.EfficientNetB0(\n",
    "        include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=\"imagenet\"\n",
    "    )\n",
    "    base.trainable = False\n",
    "\n",
    "    inp = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = base(inp, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.25)(x)\n",
    "    out = keras.layers.Dense(NUM_CLASSES, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inp, out)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(name=\"bin_acc\", threshold=threshold_metric),\n",
    "            tf.keras.metrics.AUC(curve=\"PR\", name=\"auc_pr\"),\n",
    "            tf.keras.metrics.Precision(name=\"precision\", thresholds=threshold_metric),\n",
    "            tf.keras.metrics.Recall(name=\"recall\", thresholds=threshold_metric),\n",
    "            F1Macro(NUM_CLASSES, threshold=threshold_metric, name=\"f1_macro\"),\n",
    "        ],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def finetune_unfreeze(model: keras.Model, n_layers: int = 30):\n",
    "    backbone = None\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, keras.Model) and \"efficientnet\" in layer.name:\n",
    "            backbone = layer\n",
    "            break\n",
    "    if backbone is None:\n",
    "        return\n",
    "    backbone.trainable = True\n",
    "    for l in backbone.layers[:-n_layers]:\n",
    "        l.trainable = False\n",
    "\n",
    "def load_best_model_if_exists():\n",
    "    if BEST_MODEL_PATH.exists():\n",
    "        m = keras.models.load_model(BEST_MODEL_PATH, compile=False)\n",
    "        m.compile(\n",
    "            optimizer=keras.optimizers.Adam(1e-4),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\n",
    "                tf.keras.metrics.BinaryAccuracy(name=\"bin_acc\", threshold=0.35),\n",
    "                tf.keras.metrics.AUC(curve=\"PR\", name=\"auc_pr\"),\n",
    "                tf.keras.metrics.Precision(name=\"precision\", thresholds=0.35),\n",
    "                tf.keras.metrics.Recall(name=\"recall\", thresholds=0.35),\n",
    "                F1Macro(NUM_CLASSES, threshold=0.35, name=\"f1_macro\"),\n",
    "            ],\n",
    "        )\n",
    "        return m\n",
    "    return build_model(lr=1e-3, threshold_metric=0.35)\n",
    "\n",
    "thr_vec = load_thresholds_or_default()\n",
    "model_ui = load_best_model_if_exists()\n",
    "\n",
    "print(\"Modelo listo:\", BEST_MODEL_PATH.exists(), \"| Thresholds:\", THRESH_PATH.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ebc46e24-4647-4e8f-a5ca-7a39da64d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# CELDA 8) TRAIN + LOG MLFLOW (CORREGIDO: devuelve macro_f1 float)\n",
    "# =========================================================\n",
    "def train_and_log(run_name: str, model: keras.Model, train_ds, val_ds, epochs: int, lr: float, note: str):\n",
    "    setup_mlflow()\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.set_tag(\"note\", note)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "        mlflow.log_param(\"img_size\", IMG_SIZE)\n",
    "        mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "        mlflow.log_param(\"classes\", \"|\".join(CLASSES))\n",
    "\n",
    "        hist = model.fit(train_ds, validation_data=val_ds, epochs=epochs, verbose=1)\n",
    "\n",
    "        # log últimas métricas\n",
    "        last = {k: float(v[-1]) for k, v in hist.history.items() if len(v)}\n",
    "        for k, v in last.items():\n",
    "            mlflow.log_metric(k.replace(\"@\", \"_\"), v)\n",
    "\n",
    "        # thresholds óptimos en val\n",
    "        y_true, y_prob = evaluate_probs(model, val_ds)\n",
    "        thr = find_best_thresholds(y_true, y_prob)\n",
    "        save_thresholds(thr)\n",
    "\n",
    "        # macro-f1 real con esos thresholds\n",
    "        prec, rec, f1, macro_f1 = metrics_at_thresholds(y_true, y_prob, thr)\n",
    "\n",
    "        mlflow.log_metric(\"val_macro_f1_best_thr\", float(macro_f1))\n",
    "        for i, c in enumerate(CLASSES):\n",
    "            mlflow.log_metric(f\"val_f1_{c}\", float(f1[i]))\n",
    "            mlflow.log_metric(f\"thr_{c}\", float(thr[i]))\n",
    "\n",
    "        # guardar best\n",
    "        model.save(BEST_MODEL_PATH)\n",
    "        mlflow.log_artifact(str(THRESH_PATH), artifact_path=\"artifacts\")\n",
    "        safe_log_keras_model(model, name=\"model\")\n",
    "\n",
    "        return float(macro_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b9d3710f-3a26-40f9-81e8-9487d3887522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo listo: True | Thresholds: True\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELDA 9) ENTRENAMIENTO BASE (si no existe best_multilabel.keras)\n",
    "# =========================================================\n",
    "if not BEST_MODEL_PATH.exists():\n",
    "    print(\"No existe BEST_MODEL_PATH -> entrenando modelo BASE...\")\n",
    "\n",
    "    train_ds = make_ds(raw_train, training=True, shuffle=True)\n",
    "    val_ds = make_ds(raw_val, training=False, shuffle=False)\n",
    "\n",
    "    model_base = build_model(lr=1e-3, threshold_metric=0.35)\n",
    "\n",
    "    macro_f1 = train_and_log(\n",
    "        run_name=f\"train_base_{time.strftime('%Y%m%d_%H%M%S')}\",\n",
    "        model=model_base,\n",
    "        train_ds=train_ds,\n",
    "        val_ds=val_ds,\n",
    "        epochs=8,\n",
    "        lr=1e-3,\n",
    "        note=\"Entrenamiento base inicial\"\n",
    "    )\n",
    "\n",
    "    print(f\"Base listo. Macro-F1(val, best thr)={macro_f1:.4f}\")\n",
    "\n",
    "# Recargar\n",
    "thr_vec = load_thresholds_or_default()\n",
    "model_ui = load_best_model_if_exists()\n",
    "print(\"Modelo listo:\", BEST_MODEL_PATH.exists(), \"| Thresholds:\", THRESH_PATH.exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c2bcf-4248-4004-96c3-285e592c3042",
   "metadata": {},
   "source": [
    "## Predicción\n",
    "Selecciona una imagen y el sistema mostrará:\n",
    "- Probabilidades por clase\n",
    "- Predicción final\n",
    "- Opción de corrección (feedback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ed8865-d5fa-4d0f-8831-5c9e493403b8",
   "metadata": {},
   "source": [
    "## Reentrenamiento incremental\n",
    "Al reentrenar:\n",
    "- Se mezclan datos originales + feedback\n",
    "- Se ajusta el número de epochs según cantidad de feedback\n",
    "- Se guarda el mejor modelo y se registra un nuevo run en MLflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "025c9708-4b79-4ef9-a3ac-474e0dd99bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e266421f1f340ec8ea1002926d789da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Imagen:', layout=Layout(width='65%'), options=(('Clasifica…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# CELDA 10) PREDICCIÓN + UI (solo test_images) + FEEDBACK + REENTRENAR\n",
    "# =========================================================\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def predict_one(model, img_path: Path):\n",
    "    x = decode_image(tf.convert_to_tensor(str(img_path)))\n",
    "    x = tf.expand_dims(x, 0)\n",
    "    prob = model.predict(x, verbose=0)[0]\n",
    "    return prob\n",
    "\n",
    "def pretty_print_probs(prob, thr):\n",
    "    order = np.argsort(-prob)\n",
    "    lines = []\n",
    "    for i in order:\n",
    "        estado = \"Existe\" if prob[i] >= thr[i] else \"No existe\"\n",
    "        lines.append(f\"{CLASSES[i]:10s} | {estado:9s} | prob={prob[i]:.3f} | thr={thr[i]:.2f}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def detected_labels(prob, thr):\n",
    "    labs = [CLASSES[i] for i in range(NUM_CLASSES) if prob[i] >= thr[i]]\n",
    "    if len(labs) == 0:\n",
    "        labs = [CLASSES[int(np.argmax(prob))]]\n",
    "    return labs[:3]\n",
    "\n",
    "def compute_retrain_epochs(n_fb: int) -> int:\n",
    "    if n_fb <= 2: return 2\n",
    "    if n_fb <= 5: return 4\n",
    "    if n_fb <= 10: return 6\n",
    "    return 8\n",
    "\n",
    "def compute_feedback_boost(n_fb: int) -> int:\n",
    "    if n_fb < 5: return 6\n",
    "    if n_fb < 10: return 4\n",
    "    return 2\n",
    "\n",
    "def show_preview(img_path: Path, max_side=360):\n",
    "    try:\n",
    "        im = PILImage.open(img_path).convert(\"RGB\")\n",
    "        w, h = im.size\n",
    "        scale = max(w, h) / max_side\n",
    "        if scale > 1:\n",
    "            im = im.resize((int(w/scale), int(h/scale)))\n",
    "        display(im)\n",
    "    except Exception as e:\n",
    "        print(\"No se pudo mostrar la imagen:\", e)\n",
    "\n",
    "# Widgets\n",
    "imgs = list_images(TEST_DIR)\n",
    "img_dd = widgets.Dropdown(\n",
    "    options=[(p.name, str(p)) for p in imgs] if imgs else [(\"No hay imágenes en test_images\", \"\")],\n",
    "    description=\"Imagen:\",\n",
    "    layout=widgets.Layout(width=\"65%\")\n",
    ")\n",
    "\n",
    "btn_refresh = widgets.Button(description=\"Refrescar\", button_style=\"\")\n",
    "btn_predict = widgets.Button(description=\"Predecir\", button_style=\"info\")\n",
    "btn_save = widgets.Button(description=\"Guardar corrección\", button_style=\"warning\")\n",
    "btn_retrain = widgets.Button(description=\"Reentrenar con feedback\", button_style=\"success\")\n",
    "\n",
    "labels_select = widgets.SelectMultiple(\n",
    "    options=CLASSES,\n",
    "    description=\"Correcta:\",\n",
    "    layout=widgets.Layout(width=\"65%\", height=\"110px\")\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "_last_img_path = None\n",
    "\n",
    "def get_selected_image_path():\n",
    "    global _last_img_path\n",
    "    if img_dd.value:\n",
    "        p = Path(img_dd.value)\n",
    "        if p.exists():\n",
    "            _last_img_path = p\n",
    "            return p\n",
    "    return _last_img_path\n",
    "\n",
    "def on_refresh(_):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        imgs2 = list_images(TEST_DIR)\n",
    "        img_dd.options = [(p.name, str(p)) for p in imgs2] if imgs2 else [(\"No hay imágenes en test_images\", \"\")]\n",
    "        print(\" Lista actualizada. Imágenes:\", len(imgs2))\n",
    "\n",
    "btn_refresh.on_click(on_refresh)\n",
    "\n",
    "def on_dropdown_change(change):\n",
    "    if change.get(\"name\") != \"value\":\n",
    "        return\n",
    "    with out:\n",
    "        clear_output()\n",
    "        if not change[\"new\"]:\n",
    "            print(\"Selecciona una imagen.\")\n",
    "            return\n",
    "        p = Path(change[\"new\"])\n",
    "        show_preview(p)\n",
    "        print(f\"Seleccionada: {p.name}\")\n",
    "        print(\"Presiona **Predecir**.\")\n",
    "\n",
    "img_dd.observe(on_dropdown_change, names=\"value\")\n",
    "\n",
    "def on_predict(_):\n",
    "    global model_ui, thr_vec\n",
    "    with out:\n",
    "        clear_output()\n",
    "        img_path = get_selected_image_path()\n",
    "        if img_path is None:\n",
    "            print(\"No hay imagen seleccionada.\")\n",
    "            return\n",
    "\n",
    "        show_preview(img_path)\n",
    "        prob = predict_one(model_ui, img_path)\n",
    "\n",
    "        print(\"\\nPredicción (multi-label):\")\n",
    "        print(pretty_print_probs(prob, thr_vec))\n",
    "\n",
    "        labs = detected_labels(prob, thr_vec)\n",
    "        print(\"\\nDetectado:\", labs)\n",
    "\n",
    "btn_predict.on_click(on_predict)\n",
    "\n",
    "def on_save(_):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        img_path = get_selected_image_path()\n",
    "        if img_path is None:\n",
    "            print(\"No hay imagen seleccionada.\")\n",
    "            return\n",
    "\n",
    "        show_preview(img_path)\n",
    "\n",
    "        sel = list(labels_select.value)\n",
    "        if len(sel) == 0:\n",
    "            print(\"Selecciona al menos 1 etiqueta correcta.\")\n",
    "            return\n",
    "\n",
    "        saved_path = save_feedback(img_path, sel)\n",
    "        print(\" Corrección guardada:\", saved_path.name)\n",
    "        print(\"Etiquetas:\", sel)\n",
    "        print(\"Ahora puedes presionar **Reentrenar con feedback**.\")\n",
    "\n",
    "btn_save.on_click(on_save)\n",
    "\n",
    "def on_retrain(_):\n",
    "    global model_ui, thr_vec\n",
    "    with out:\n",
    "        clear_output()\n",
    "\n",
    "        fb = load_feedback_records()\n",
    "        if len(fb) == 0:\n",
    "            print(\"No hay feedback aún. Primero guarda correcciones.\")\n",
    "            return\n",
    "\n",
    "        boost = compute_feedback_boost(len(fb))\n",
    "        fb_aug = fb * boost\n",
    "\n",
    "        raw_train, raw_val = build_raw_records(train_split=0.8)\n",
    "        retrain_records = raw_train + fb_aug\n",
    "\n",
    "        train_ds = make_ds(retrain_records, training=True, shuffle=True)\n",
    "        val_ds = make_ds(raw_val, training=False, shuffle=False)\n",
    "\n",
    "        model_ui = load_best_model_if_exists()\n",
    "\n",
    "        if len(fb) >= 10:\n",
    "            finetune_unfreeze(model_ui, n_layers=30)\n",
    "            lr = 1e-4\n",
    "            note = f\"Reentreno fine-tune. fb={len(fb)} boost={boost}\"\n",
    "        else:\n",
    "            lr = 2e-4\n",
    "            note = f\"Reentreno head. fb={len(fb)} boost={boost}\"\n",
    "\n",
    "        model_ui.compile(\n",
    "            optimizer=keras.optimizers.Adam(lr),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\n",
    "                tf.keras.metrics.BinaryAccuracy(name=\"bin_acc\", threshold=0.35),\n",
    "                tf.keras.metrics.AUC(curve=\"PR\", name=\"auc_pr\"),\n",
    "                tf.keras.metrics.Precision(name=\"precision\", thresholds=0.35),\n",
    "                tf.keras.metrics.Recall(name=\"recall\", thresholds=0.35),\n",
    "                F1Macro(NUM_CLASSES, threshold=0.35, name=\"f1_macro\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        epochs = compute_retrain_epochs(len(fb))\n",
    "        print(f\" Reentrenando... epochs={epochs} | fb={len(fb)} | boost={boost} | lr={lr}\")\n",
    "\n",
    "        macro_f1 = train_and_log(\n",
    "            run_name=f\"retrain_{time.strftime('%Y%m%d_%H%M%S')}\",\n",
    "            model=model_ui,\n",
    "            train_ds=train_ds,\n",
    "            val_ds=val_ds,\n",
    "            epochs=epochs,\n",
    "            lr=lr,\n",
    "            note=note\n",
    "        )\n",
    "\n",
    "        thr_vec = load_thresholds_or_default()\n",
    "        model_ui = load_best_model_if_exists()\n",
    "\n",
    "        print(f\" Listo. Macro-F1(val, best thr)={macro_f1:.4f}\")\n",
    "        print(\"Thresholds recargados. Ahora vuelve a presionar **Predecir**.\")\n",
    "\n",
    "btn_retrain.on_click(on_retrain)\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    widgets.HBox([img_dd, btn_refresh, btn_predict]),\n",
    "    labels_select,\n",
    "    widgets.HBox([btn_save, btn_retrain]),\n",
    "    out\n",
    "])\n",
    "\n",
    "display(ui)\n",
    "\n",
    "# preview inicial\n",
    "if img_dd.value:\n",
    "    on_dropdown_change({\"name\":\"value\", \"new\": img_dd.value})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "82cc6a16-8366-4897-9471-f832c06d182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: C:\\Users\\leoos\\Examen_Segundo_Interciclo\n",
      "Tracking URI: file:///C:/Users/leoos/Examen_Segundo_Interciclo/mlruns\n",
      "Existe ./mlruns ? True\n",
      "Existe ./mlflow.db ? True\n"
     ]
    }
   ],
   "source": [
    "import mlflow, os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"Tracking URI:\", mlflow.get_tracking_uri())\n",
    "\n",
    "print(\"Existe ./mlruns ?\", (Path.cwd()/ \"mlruns\").exists())\n",
    "print(\"Existe ./mlflow.db ?\", (Path.cwd()/ \"mlflow.db\").exists())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
